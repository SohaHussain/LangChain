{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9WyfCNLINKSAAafxY/jx+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SohaHussain/LangChain/blob/main/Document_Splitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Document Splitting\n"
      ],
      "metadata": {
        "id": "wcfFmiKjO-v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document splitting happens after you load your data\n",
        "into the document format and before\n",
        "it goes into the vector store."
      ],
      "metadata": {
        "id": "vlXC8tMGdyxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basis\n",
        "of all the text splitters in Lang Chain involves splitting on\n",
        "chunks in some chunk size with\n",
        "some chunk overlap. A chunk overlap is generally kept as a\n",
        "little overlap between two chunks, like a sliding window as we\n",
        "move from one to the other. And this allows for\n",
        "the same piece of context to be at the end of one chunk and at the\n",
        "start of the other and helps create some\n",
        "notion of consistency."
      ],
      "metadata": {
        "id": "ZJtzsuYMfXZo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHw1XHl6MxyW",
        "outputId": "90b10b8c-e9ff-4cd4-ea0e-1f2598e703b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.283-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
            "  Downloading langsmith-0.0.33-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.2.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.283 langsmith-0.0.33 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "Vf128gXRPOoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947bd0c9-9c95-4162-9207-f7bc16ebb053"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/76.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDbRcut5lQuL",
        "outputId": "d978aa30-6190-4f77-dd2a-e057170a754f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.15.5-py3-none-any.whl (272 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/272.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/272.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.6/272.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.15.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyz5ybqXohDg",
        "outputId": "069209c6-9962-4eca-8724-9298daa9e4ae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import langchain\n",
        "openai_key = '##'"
      ],
      "metadata": {
        "id": "lp_y219gbRxi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
      ],
      "metadata": {
        "id": "gC3NgR0GcAj6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size =26\n",
        "chunk_overlap = 4"
      ],
      "metadata": {
        "id": "0Y4oq8ozcHYb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")\n",
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap\n",
        ")"
      ],
      "metadata": {
        "id": "_rQn_52KcS4I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
        "r_splitter.split_text(text1) # gives the same string as chunk size is 26"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxKkjSS6clkV",
        "outputId": "c94ff2bb-7b10-48cd-a754-9cea9bc2babc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abcdefghijklmnopqrstuvwxyz']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
        "r_splitter.split_text(text2) # last 4 letters are repeated because chunk overlap is 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Paoo5CTedLjB",
        "outputId": "5b75db8d-14a3-4f64-8ec6-6d8e66223feb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Recursive Splitting"
      ],
      "metadata": {
        "id": "FI_tn_D1h_iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
        "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
        "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
        "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
        "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
        "Sentences have a period at the end, but also, have a space.\\\n",
        "and words are separated by space.\"\"\""
      ],
      "metadata": {
        "id": "O_PMG395dYAS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(some_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QkFgDX8iFo3",
        "outputId": "38c0ea4d-9c66-44e7-8889-3e5bfc4f5911"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "496"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter = CharacterTextSplitter(\n",
        "    chunk_size=450,\n",
        "    chunk_overlap=0,\n",
        "    separator = ' '\n",
        ")\n",
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=450,\n",
        "    chunk_overlap=0,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"] # What this mean is that when you're splitting a piece of text it will first try to split it by double newlines.\n",
        "                                       # And then, if it still needs to split the individual chunks more it will go on to single newlines. And then, if it\n",
        "                                       # still needs to do more it goes on to the space. And then, finally it will just go character by character if it really needs to do that.\n",
        ")"
      ],
      "metadata": {
        "id": "nFm8SlbZijJR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_splitter.split_text(some_text) # character text splitter splits on spaces. And so, we end up with the weird separation in the middle of the sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCzHUss4imr4",
        "outputId": "917139c8-b487-4806-ac81-9164bac3c8c5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
              " 'have a space.and words are separated by space.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter.split_text(some_text) # The recursive text splitter first tries to split on double newlines, and so here it splits it up into two paragraphs.\n",
        "                                 # Even though the first one is shorter than the 450 characters, we specified this is probably a better split because now the two\n",
        "                                 # paragraphs that are each their own paragraphs are in the chunks as opposed to being split in the middle of a sentence."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCYU10XKjSWm",
        "outputId": "4d2cf9e2-c92f-4756-edd8-6e7fbdd24dd3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
              " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=150, # reducing the chunk size\n",
        "    chunk_overlap=0,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
        ")\n",
        "r_splitter.split_text(some_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XibfSgckkfsz",
        "outputId": "2797707a-3930-4424-ff77-1699520a228d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
              " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
              " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
              " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/MachineLearning-Lecture01.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "3neV45cik6IH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150,\n",
        "    length_function=len\n",
        ")"
      ],
      "metadata": {
        "id": "CUAtiloGlNTD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = text_splitter.split_documents(pages)\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_wlgjQwld2Q",
        "outputId": "d4a26470-9c3d-4468-9767-f60b692cb191"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvKmhSL2l3j8",
        "outputId": "26aab13a-534c-48bb-9a17-5f20a2cbdeda"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token Splitting"
      ],
      "metadata": {
        "id": "AsJ6QThOn0A-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason that this is useful is because often LLMs have context\n",
        "windows that are designated by token count. And so,\n",
        "it's important to know what the tokens are, and\n",
        "where they appear. And then, we can split on them to have a slightly\n",
        "more representative idea of how the LLM would view them."
      ],
      "metadata": {
        "id": "OrgEjxLPoKUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import TokenTextSplitter"
      ],
      "metadata": {
        "id": "1YpQRIUKl7CZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
      ],
      "metadata": {
        "id": "l6RDSoCOoXe6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter.split_text(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EirlMbT8oaxW",
        "outputId": "62c5e503-7da3-4cd4-bbcf-87528f90e72a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abc',\n",
              " 'def',\n",
              " 'gh',\n",
              " 'ij',\n",
              " 'kl',\n",
              " 'mn',\n",
              " 'op',\n",
              " 'q',\n",
              " 'r',\n",
              " 'st',\n",
              " 'uv',\n",
              " 'w',\n",
              " 'xy',\n",
              " 'z']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_XO2RzqoqTT",
        "outputId": "a04daa5d-7b8a-4a45-977c-01633febe1f5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='MachineLearning-Lecture01  \\n', metadata={'source': '/content/MachineLearning-Lecture01.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pages[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUy3V-m6o0XU",
        "outputId": "f6b7ec41-5d8c-4e6b-8ddb-5e2fcea87da1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': '/content/MachineLearning-Lecture01.pdf', 'page': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuLUhnQLo5ph",
        "outputId": "b767e2e7-43e4-47dd-deae-41f0d742b9fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Instructor (Andrew Ng):  Okay. Good', metadata={'source': '/content/MachineLearning-Lecture01.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Context Aware Splitting"
      ],
      "metadata": {
        "id": "QdIrVed5rvX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking aims to keep text with common context together.\n",
        "\n",
        "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
        "\n",
        "We can use MarkdownHeaderTextSplitter to preserve header metadata in our chunks."
      ],
      "metadata": {
        "id": "UFC5sgGrsKyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import MarkdownHeaderTextSplitter"
      ],
      "metadata": {
        "id": "bZTOaedVrrMr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markdown_document = \"\"\"# Title\\n\\n \\\n",
        "## Chapter 1\\n\\n \\\n",
        "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
        "### Section \\n\\n \\\n",
        "Hi this is Lance \\n\\n\n",
        "## Chapter 2\\n\\n \\\n",
        "Hi this is Molly\"\"\""
      ],
      "metadata": {
        "id": "J2OfqD4BsUC7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\"),\n",
        "]"
      ],
      "metadata": {
        "id": "2TRwet4QsWur"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markdown_splitter = MarkdownHeaderTextSplitter(\n",
        "    headers_to_split_on=headers_to_split_on\n",
        ")\n",
        "md_header_splits = markdown_splitter.split_text(markdown_document)"
      ],
      "metadata": {
        "id": "Sq3iK6MfsZZy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_header_splits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu3X3dtPsg61",
        "outputId": "99d8e60e-6a0a-42d3-9bca-afc548dabc27"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "md_header_splits[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7IKA1CTsj2H",
        "outputId": "10dc974d-aa9b-4544-c108-58989a986746"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LA_uuMNPslZX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}